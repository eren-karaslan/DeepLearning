# -*- coding: utf-8 -*-
"""RNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/167nNrY7hIIvhO9sPbv58qAqmwZhp7fHA

1)Understanding data

2)Data preparing

3)Modelling

4)Evaluation

1)Understanding data`
"""

import numpy as np
import pandas as pd
import datetime as dt
import tensorflow as tf
import matplotlib.pyplot as plt

#Model evaluation and data scaling libraries
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error

#Libraries for modelling
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,SimpleRNN,Dropout
from tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping

#Prevent warnings
import warnings
warnings.filterwarnings('ignore')

#Tensorflow prevent warning
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

dir_path= '/content/drive/MyDrive/international-airline-passengers.csv'
print(dir_path)

df=pd.read_csv(dir_path)
df.head()

df.columns

df.columns=['Month','Passengers']
print(df.columns)

df.tail()

df.shape

df.dtypes

df.isnull().sum()

df.describe().T

"""2)Data preparing"""

df=df[0:144] #last line deleted because it has false data

df['Month'] = pd.to_datetime(df['Month']) #Month varaible's type was object,converted to datetime

df.info()

print("Minimum Date: ",df["Month"].min())
print("Maksimum Date: ",df["Month"].max())

df.index=df["Month"] #now indexs converted from numbers to date

df.head()

df.drop("Month", axis=1, inplace=True) #month column deleted,axis=1 for column axis=0 for row,inplace=True for permanent deleted

df.head()

result_df=df.copy()

df.plot(figsize=(14,8),title='Monthly airline passengers')

"""** The data are in dataframe form.For modeling, The data have to be in pandas array form."""

data=df["Passengers"].values

#data.head() this command give a error because data are numpy array now
data[0:5]
type(data[0:5])

type(data[0]) #type of data is float 64

data=data.astype('float32') #convert to float32
type(data[0])

data.shape

data=data.reshape(-1,1) #adjusting dimension
data.shape

"""**We cannot use sklearn for RNN (Recurrent Neural Network) because sklearn randomly splits the data, but we need sequential data."""

from tensorflow.python.ops.gen_array_ops import tensor_scatter_max_eager_fallback
def split_data(dataframe, test_size):
  position = int(round(len(dataframe) * (1-test_size)))
  train = dataframe[:position]
  test = dataframe[position:]
  return train,test,position

train,test,position = split_data(data,0.33)

print(train.shape,test.shape)

scaler_train = MinMaxScaler(feature_range = (0,1))
train = scaler_train.fit_transform(train)
scaler_test = MinMaxScaler(feature_range = (0,1))
test = scaler_test.fit_transform(test)

train[0:5]

test[0:5]

def create_features(data,lookback):
  X,Y = [],[]
  for i in range(lookback,len(data)):
    X.append(data[i-lookback:i,0])
    Y.append(data[i,0])
  return np.array(X),np.array(Y)

lookback=1

X_train,y_train = create_features(train,lookback)
X_test,y_test = create_features(test,lookback)

print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)

#For RNN data have to be 3 dimensions
X_train= np.reshape(X_train,(X_train.shape[0], 1 ,X_train.shape[1]))
X_test=  np.reshape(X_test,(X_test.shape[0], 1 ,X_test.shape[1]))
y_train= y_train.reshape(-1,1)
y_test=  y_test.reshape(-1,1)

print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)

"""3)MODELING"""

model=Sequential()

model.add(SimpleRNN(units=50,
                    activation='relu',
                    input_shape=(X_train.shape[1], lookback)))
model.add(Dropout(0.2))
model.add(Dense(1)) #For output,one cell enough because we expect one result(number).

model.summary()

#Adjusting Optimization ve Evaluation Metrics

model.compile(loss='mean_squared_error' , optimizer='adam')

callbacks=[EarlyStopping(monitor='val_loss',patience=3,verbose=1,mode='min'),
           ModelCheckpoint(filepath='mymodel.h5',monitor='val_loss',mode='min',
                           save_best_only=True,save_weights_only=False,verbose=1)]

history=model.fit(x=X_train,
                  y=y_train,
                  epochs=50,
                  batch_size=1,
                  validation_data=(X_test,y_test),
                  callbacks=callbacks,
                  shuffle=False) #if shuffle=false data is not shuffled

plt.figure(figsize=(20,5))
plt.subplot(1,2,2)
plt.plot(history.history['loss'],label='Training Loss')
plt.plot(history.history['val_loss'],label='Validation Loss')
plt.legend(loc='upper right')
plt.xlabel('Epoch' ,fontsize=16)
plt.ylabel('Loss' ,fontsize=16)
plt.ylim([0,max(plt.ylim())])
plt.title('training and Validation Loss',fontsize=16)
plt.show()

"""4)Evaluation"""

loss = model.evaluate(X_test,y_test,batch_size=1)
print("\nTest loss: %.1f%%" % (100.0 * loss))

train_predict=model.predict(X_train)

test_predict=model.predict(X_test)

train_predict=scaler_train.inverse_transform(train_predict)
test_predict=scaler_test.inverse_transform(test_predict)  #We are converting the values back to their original range, which is between 0 and 1.

y_train=scaler_train.inverse_transform(y_train)  #We have restored the values to their original state in the original data.
y_test=scaler_test.inverse_transform(y_test)

#RMSE value of Train
train_rmse= np.sqrt(mean_squared_error(y_train,train_predict))

#RMSE value of test
test_rmse= np.sqrt(mean_squared_error(y_test,test_predict))

print(f"Train RMSE: {train_rmse}")
print(f"Test RMSE: {test_rmse}")

df.describe().T

train_prediction_df=result_df[lookback:position]

train_prediction_df["Predicted"] = train_predict

train_prediction_df.head()

test_prediction_df=result_df[position+lookback:]
test_prediction_df["Predicted"] = test_predict
test_prediction_df.head()
