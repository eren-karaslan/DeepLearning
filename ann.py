# -*- coding: utf-8 -*-
"""ANN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pg9N0yASLzsyoz1a_c_WfkrAGZzDhjq6
"""

import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import load_model,Sequential
from tensorflow.keras.layers import Dense,Flatten
from tensorflow.keras.utils import to_categorical,plot_model

import matplotlib.pyplot as plt
import numpy as np

import warnings
from warnings import filterwarnings
warnings.filterwarnings("ignore",category=DeprecationWarning)
warnings.filterwarnings("ignore",category=FutureWarning)
warnings.filterwarnings("ignore",category=UserWarning)
filterwarnings("ignore")

#Mnist data loading
(x_train, y_train), (x_test, y_test) = mnist.load_data()

print("Eğitim seti boyutu: ",x_train.shape,y_train.shape)
print("Test seti boyutu: ",x_test.shape,y_test.shape)

num_labels=len(np.unique(y_train))

#Examples of dataset
plt.figure(figsize=(10,10))
plt.imshow(x_train[2],cmap='gray')


plt.figure(figsize=(10,10)) #2 row * 5 column showing first 10 photos
for n in range(10):
  ax=plt.subplot(5,5,n+1)
  plt.imshow(x_train[n],cmap='gray')
  plt.axis("off")

#this is function
def visualize_img(data):
   plt.figure(figsize=(10,10))
   for n in range(10):
      ax=plt.subplot(5,5,n+1)
      plt.imshow(x_train[n],cmap='gray')
      plt.axis("off")

x_train[2]

x_train[2][10,10]#0 reprensts black 255 represents white

x_train[2].sum() #rgb code sum of all colors in the photo of 2 elements in the dataset

x_train[2][14:20 , 10:20]#

x_train[2][14:20 , 10:20].mean()

#function that gives the rgb values ​​of the pixels in the picture
def pixel_visualizing(img):
  fig = plt.figure(figsize=(12,12))
  ax=fig.add_subplot(111)
  ax.imshow(img, cmap="gray")
  width,height= img.shape

  threshold=img.max() / 2.5

  for x in range(width):
    for y in range(height):
      ax.annotate(str(round(img[x][y], 2)),xy=(y,x),
                  color="white" if img[x][y]<threshold else "black")

pixel_visualizing(x_train[2])

"""# 3)Data preparing

1)Encoding

 before [0 1 2 3 4 5 6 7]

 after  [0 0 1 0 0 0 0 0]

if the value is 2 equal to 1 , others equal to zero
"""

y_train[0:5]

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

y_train[0:5]

"""2) Reshaping"""

image_size=x_train.shape[1]
image_size

print(f"x_train dimension:  {x_train.shape}")
print(f"x_test dimension:  {x_test.shape}")

x_train = x_train.reshape(x_train.shape[0],28,28,1)
x_test = x_test.reshape(x_test.shape[0],28,28,1)

print(f"x_train dimension:  {x_train.shape}")
print(f"x_test dimension:  {x_test.shape}")

"""3)Standardize"""

x_train=x_train.astype('float32') / 255
x_test=x_test.astype('float32') / 255

"""# 4)MODELING

Set up Model
"""

model = tf.keras.Sequential([
    Flatten(input_shape=(28,28,1)), #input shaping
    Dense(units=128,activation="relu",name="layer1"), #Consists of 128 neurons
    Dense(units=num_labels, activation="softmax",name="output_layer")])

model.compile(loss="categorical_crossentropy", #goal is to minimize categorical_crossentropy
              optimizer="adam", #minimize edecek algoritma yöntemi
              metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),"accuracy"]) #metrics velues

model.summary()

model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test,y_test))

"""# 5)Evaluating  Model Success"""

history=model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test,y_test))

####################################
#Accuarcy ve Loss Grafikleri
####################################

#-------------------------Grafik 1 Accuracy-----------------------------
plt.figure(figsize=(20,5))
plt.subplot(1,2,1)
plt.plot(history.history["accuracy"],color="b",label="Training Accuracy")
plt.plot(history.history["val_accuracy"], color="r", label="Validation Accuracy")
plt.legend(loc="lower right")
plt.xlabel("Epoch", fontsize=16)
plt.ylabel("Accuracy",fontsize=16)
plt.ylim([min(plt.ylim()),1])
plt.title("Train and Test Accıracy Graph", fontsize=16)

#-------------------------Grafik 1 Loss-----------------------------
plt.subplot(1,2,2)
plt.plot(history.history["loss"],color="b",label="Training Loss")
plt.plot(history.history["val_loss"], color="r", label="Validation Loss")
plt.legend(loc="upper right")
plt.xlabel("Epoch", fontsize=16)
plt.ylabel("Loss",fontsize=16)
plt.ylim([0,max(plt.ylim())])
plt.title("Train and Test Loss Graph", fontsize=16)
plt.show()

loss,precision,recall,acc=model.evaluate(x_test,y_test,verbose="False")
print("\nTest Accuracy: %.3f%%" % (100.0 * acc))
print("\nTest Loss: %.2f" % (100.0 * loss))
print("\nTest Precision: %.2f" % (100.0 * precision))
print("\nTest Recall: %.2f" % (100.0 * recall))

"""# Saving the Model and Using for Estimation"""

model.save("mnist_model.h5")

import random
random=random.randint(0,x_test.shape[0])

random

test_image=x_test[random] #Taking images here

y_test[random] #Taking number here

plt.imshow(test_image.reshape(28,28),cmap="gray")

test_data=x_test[random].reshape(1,28,28,1)

probability=model.predict(test_data)

probability #Prediction values ​​given to which number that number might be

predicted_classes=np.argmax(probability)

predicted_classes

print(f"Predicted Class: {predicted_classes} \n")
print(f"Probability of Predicted Class: {(np.max(probability,axis=1))[0]} \n")
print(f"Probability of Other Class: \n{probability}")